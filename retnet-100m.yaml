vocab_size: 50257
hidden_size: 960
num_layers: 8
num_heads: 8
qk_dim: 960
v_dim: 1920
ffn_proj_size: 1920
use_bias_in_msr: False
use_bias_in_mlp: True
use_bias_in_msr_out: False
use_default_gamma: False
initializer_range: 0.02
output_retentions: False
pad_token_id: 50256
eos_token_id: 50256
unk_token_id: 50256